upper=dataind['bmr'].quantile(0.995,
interpolation="higher"))
dataind['bmrw'].describe()
plt.clf()
sns.histplot(data=dataind,x='bmrw')
plt.show()
dataind['revgrowth'].describe()
dataind['revgrowthw']=dataind['revgrowth'].clip(lower=dataind['revgrowth'].quantile(0.002,interpolation="lower"),
upper=dataind['revgrowth'].quantile(0.995,
interpolation="higher"))
dataind['revgrowthw'].describe()
plt.clf()
sns.histplot(data=dataind,x='revgrowthw')
plt.show()
dataind['revgrowth'].describe()
dataind['revgrowthw']=dataind['revgrowth'].clip(lower=dataind['revgrowth'].quantile(0.001,interpolation="lower"),
upper=dataind['revgrowth'].quantile(0.99,
interpolation="higher"))
dataind['revgrowthw'].describe()
plt.clf()
sns.histplot(data=dataind,x='revgrowthw')
plt.show()
dataind['revgrowth'].describe()
dataind['revgrowthw']=dataind['revgrowth'].clip(lower=dataind['revgrowth'].quantile(0.0005,interpolation="lower"),
upper=dataind['revgrowth'].quantile(0.985,
interpolation="higher"))
dataind['revgrowthw'].describe()
plt.clf()
sns.histplot(data=dataind,x='revgrowthw')
plt.show()
dataind['egrowth'].describe()
dataind['egrowthw']=dataind['egrowth'].clip(lower=dataind['egrowth'].quantile(0.01,interpolation="lower"),
upper=dataind['egrowth'].quantile(0.985,
interpolation="higher"))
dataind['egrowthw'].describe()
plt.clf()
sns.histplot(data=dataind,x='egrowthw')
plt.show()
dataind['size']=np.log(dataind['mvalue'])
plt.clf()
sns.histplot(data=dataind,x='size')
plt.show()
dataind['sizegroup'] = dataind.groupby(dataind['q'])['marketvalue'].transform(lambda x: pd.qcut(x,3,labels=["small","medium","large"]))
# I check how many firms where classified in each group:
dataind.groupby('sizegroup')['sizegroup'].count()
dataind['sizegroup'] = dataind.groupby(dataind['q'])['marketvalue'].transform(lambda x: pd.qcut(x,3,labels=["small","medium","large"]))
# I check how many firms where classified in each group:
dataind.groupby('sizegroup')['sizegroup'].count()
View(dataind)
dataind['sizegroup'] = dataind.groupby(dataind['q'])['mvalue'].transform(lambda x: pd.qcut(x,3,labels=["small","medium","large"]))
# I check how many firms where classified in each group:
dataind.groupby('sizegroup')['sizegroup'].count()
pd.crosstab(index=dataind['q'],columns='count')
pd.crosstab(index=dataind['q'],columns=dataind['sizegroup'])
dataind['sizegroup'] = dataind.groupby(dataind['yearf'])['mvalue'].transform(lambda x: pd.qcut(x,3,labels=["small","medium","large"]))
# I check how many firms where classified in each group:
dataind.groupby('sizegroup')['sizegroup'].count()
pd.crosstab(index=dataind['q'],columns='count')
pd.crosstab(index=dataind['q'],columns=dataind['sizegroup'])
dataind['sizegroup'] = dataind.groupby(dataind['yearf'])['mvalue'].transform(lambda x: pd.qcut(x,3,labels=["small","medium","large"]))
# I check how many firms where classified in each group:
dataind.groupby('sizegroup')['sizegroup'].count()
pd.crosstab(index=dataind['yearf'],columns='count')
pd.crosstab(index=dataind['yearf'],columns=dataind['sizegroup'])
# I replicate the sizegroup variable since the get_dummies function drops the original categorical variable
dataind['sizeg'] = dataind['sizegroup']
# I create the dummies of sizeg.
dataind = pd.get_dummies(dataind,columns=['sizeg'],drop_first=True, dummy_na=True)
# The new dataind_dummies dataset has all the columns of dataind plus the 3 dummies: 2 for size group and one to identify NA values
# The get_dummies function assign 0 to the new dummies if the categorical value has NA value, so I will set as nan when the sizeg has NA:
dataind.loc[dataind.sizeg_nan == 1, ["sizeg_medium","sizeg_large"]] = np.nan
# I select one industry
numind = 1
#numind = 2
#numind = 3
#numind = 4
print(numind)
datay = data.loc[(data['fiscalmonth']==12)].copy()
if numind==1:
dataind = datay.loc[(datay['industria']=="Industrias manufactureras")].copy()
elif numind==2:
dataind = datay.loc[(datay['industria']=="Comercio al por menor") |
((datay['industria']=="Comercio al por mayor"))].copy()
elif numind==3:
dataind = datay.loc[((data['industria']=="Servicios de alojamiento temporal y de preparación de alimentos y bebidas")) |
((datay['industria']=="Servicios de apoyo a los negocios y manejo de residuos y desechos, y servicios de remediación")) |
((datay['industria']=="Servicios de esparcimiento culturales y deportivos, y otros servicios recreativos")) |
((datay['industria']=="Servicios de salud y de asistencia social")) |
((datay['industria']=="Servicios educativos")) |
((datay['industria']=="Servicios inmobiliarios y de alquiler de bienes muebles e intangibles")) |
((datay['industria']=="Servicios profesionales, científicos y técnicos")) |
((datay['industria']=="Transportes, correos y almacenamiento"))].copy()
else:
dataind = datay.loc[((datay['industria']=="Servicios financieros y de seguros"))].copy()
data2022ind = dataind.loc[(data['yearf']==2022)].copy()
# I reset the index since this dataset is not a panel data (it's a cross-sectional)
data2022ind=data2022ind.reset_index()
# I drop the qdate column:
data2022ind.drop(axis=1,columns=['qdate'],inplace=True)
data2022ind.head(4)
# earnings per share
dataind['eps'] = np.where(dataind['sharesoutstanding']==0,np.NaN,dataind['netincome'] / dataind['sharesoutstanding'])
# I need to validate whether the denominator is 0
dataind['epsp'] = np.where(dataind['originalprice']==0,np.NaN,dataind['eps'] / dataind['originalprice'])
# For market value I use originalprice that is the historical stock price without considering
#    stocks splits. I do this since sharesoutstanding is the # of historical shares
# operating earnings per share
dataind['oeps'] = np.where(dataind['sharesoutstanding']==0,np.NaN,dataind['ebit'] / dataind['sharesoutstanding'])
# I need to validate whether the denominator is 0
dataind['oepsp'] = np.where(dataind['originalprice']==0,np.NaN,dataind['oeps'] / dataind['originalprice'])
dataind['bmr'] = np.where(dataind['mvalue']==0,np.NaN,(dataind['totalassets'] - dataind['totalliabilities']) / dataind['mvalue'])
# Revenue annual growth:
dataind['revgrowth'] = np.where(dataind.groupby(['firm'])['revenue'].shift(4)==0,np.NaN,
dataind['revenue'] / dataind.groupby(['firm'])['revenue'].shift(4) - 1)
# Operating earnings growth:
dataind['egrowth'] = np.where(dataind.groupby(['firm'])['ebit'].shift(4)==0,np.NaN,
dataind['ebit'] / dataind.groupby(['firm'])['ebit'].shift(4) - 1)
ratiossummary= dataind.agg(
{
"epsp": ["min","max","median"],
"oepsp": ["min","max","median"],
"bmr": ["min","max","median"],
"revgrowth": ["min","max","median"],
"egrowth": ["min","max","median"]
}
)
ratiossummary
dataind['oepsp'].describe()
#dataind['epspw']=winsorize(dataind['epsp'],(0.01,0.99), nan_policy='omit')
# It seems that winsorize has problems with NaN values; it did not work
#I will use the clip method of pandas to do the winsorization:
dataind['oepspw']=dataind['oepsp'].clip(lower=dataind['oepsp'].quantile(0.008,
interpolation="lower"),
upper=dataind['oepsp'].quantile(0.999,
interpolation="higher"))
dataind['oepspw'].describe()
dataind['pm'].describe()
dataind['pmw']=dataind['pm'].clip(lower=dataind['pm'].quantile(0.01,interpolation="lower"),
upper=dataind['pm'].quantile(0.985,
interpolation="higher"))
dataind['pmw'].describe()
plt.clf()
sns.histplot(data=dataind,x='pmw')
plt.show()
dataind['pm'].describe()
dataind['pmw']=dataind['pm'].clip(lower=dataind['pm'].quantile(0.02,interpolation="lower"),
upper=dataind['pm'].quantile(0.99,
interpolation="higher"))
dataind['pmw'].describe()
plt.clf()
sns.histplot(data=dataind,x='pmw')
plt.show()
dataind['pm'].describe()
dataind['pmw']=dataind['pm'].clip(lower=dataind['pm'].quantile(0.02,interpolation="lower"),
upper=dataind['pm'].quantile(0.999,
interpolation="higher"))
dataind['pmw'].describe()
plt.clf()
sns.histplot(data=dataind,x='pmw')
plt.show()
dataind['ato'].describe()
dataind['atow']=dataind['ato'].clip(lower=dataind['ato'].quantile(0.01,interpolation="lower"),
upper=dataind['ato'].quantile(0.985,
interpolation="higher"))
dataind['atow'].describe()
plt.clf()
sns.histplot(data=dataind,x='atow')
plt.show()
dataind['ato'].describe()
dataind['atow']=dataind['ato'].clip(lower=dataind['ato'].quantile(0.001,interpolation="lower"),
upper=dataind['ato'].quantile(0.995,
interpolation="higher"))
dataind['atow'].describe()
plt.clf()
sns.histplot(data=dataind,x='atow')
plt.show()
dataind['ato'].describe()
dataind['atow']=dataind['ato'].clip(lower=dataind['ato'].quantile(0.001,interpolation="lower"),
upper=dataind['ato'].quantile(0.99,
interpolation="higher"))
dataind['atow'].describe()
plt.clf()
sns.histplot(data=dataind,x='atow')
plt.show()
dataind['ato'].describe()
dataind['atow']=dataind['ato'].clip(lower=dataind['ato'].quantile(0.001,interpolation="lower"),
upper=dataind['ato'].quantile(0.995,
interpolation="higher"))
dataind['atow'].describe()
plt.clf()
sns.histplot(data=dataind,x='atow')
plt.show()
dataind['ato'].describe()
dataind['atow']=dataind['ato'].clip(lower=dataind['ato'].quantile(0.001,interpolation="lower"),
upper=dataind['ato'].quantile(0.999,
interpolation="higher"))
dataind['atow'].describe()
plt.clf()
sns.histplot(data=dataind,x='atow')
plt.show()
dataind['size']=np.log(dataind['mvalue'])
plt.clf()
sns.histplot(data=dataind,x='size')
plt.show()
dataind['size'].describe()
dataind['size']=np.where(dataind['size']==0,NaN,np.log(dataind['mvalue'])
plt.clf()
sns.histplot(data=dataind,x='size')
plt.show()
dataind['size'].describe()
dataind['size']=np.where(dataind['size']==0,NaN,np.log(dataind['mvalue']))
plt.clf()
sns.histplot(data=dataind,x='size')
plt.show()
dataind['size'].describe()
dataind['size']=np.where(dataind['size']==0,nan,np.log(dataind['mvalue']))
plt.clf()
sns.histplot(data=dataind,x='size')
plt.show()
dataind['size'].describe()
dataind['size']=np.where(dataind['size']==0,np.NaN,np.log(dataind['mvalue']))
plt.clf()
sns.histplot(data=dataind,x='size')
plt.show()
dataind['size'].describe()
dataind['size']=np.where(dataind['mvalue']==0,np.NaN,np.log(dataind['mvalue']))
plt.clf()
sns.histplot(data=dataind,x='size')
plt.show()
dataind['size'].describe()
dataind['sizegroup'] = dataind.groupby(dataind['yearf'])['mvalue'].transform(lambda x: pd.qcut(x,3,labels=["small","medium","large"]))
# I check how many firms where classified in each group:
dataind.groupby('sizegroup')['sizegroup'].count()
pd.crosstab(index=dataind['yearf'],columns='count')
pd.crosstab(index=dataind['yearf'],columns=dataind['sizegroup'])
dataind['sizegroup'] = dataind.groupby(dataind['yearf'])['mvalue'].transform(lambda x: pd.qcut(x,3,labels=["small","medium","large"]))
# I check how many firms where classified in each group:
#dataind.groupby('sizegroup')['sizegroup'].count()
pd.crosstab(index=dataind['yearf'],columns='count')
pd.crosstab(index=dataind['yearf'],columns=dataind['sizegroup'])
pd.crosstab(index=dataind['yearf'],columns='count')
pd.crosstab(index=dataind['yearf'],columns=dataind['sizegroup'])
#pd.crosstab(index=dataind['yearf'],columns='count')
pd.crosstab(index=dataind['yearf'],columns=dataind['sizegroup'])
# I replicate the sizegroup variable since the get_dummies function drops the original categorical variable
dataind['sizeg'] = dataind['sizegroup']
# I create the dummies of sizeg.
dataind = pd.get_dummies(dataind,columns=['sizeg'],drop_first=True, dummy_na=True)
# The new dataind_dummies dataset has all the columns of dataind plus the 3 dummies: 2 for size group and one to identify NA values
# The get_dummies function assign 0 to the new dummies if the categorical value has NA value, so I will set as nan when the sizeg has NA:
dataind.loc[dataind.sizeg_nan == 1, ["sizeg_medium","sizeg_large"]] = np.nan
XY = dataind[["f1ry","epspw","oepspw","bmrw","revgrowthw","egrowthw","pmw","atow","sizeg_medium","sizeg_large"]]
XY[["f1ry","epspw","oepspw","bmrw","revgrowthw","egrowthw","pmw","atow"]].describe()
dataind['oepsp'].describe()
#dataind['epspw']=winsorize(dataind['epsp'],(0.01,0.99), nan_policy='omit')
# It seems that winsorize has problems with NaN values; it did not work
#I will use the clip method of pandas to do the winsorization:
dataind['oepspw']=dataind['oepsp'].clip(lower=dataind['oepsp'].quantile(0.008,
interpolation="lower"),
upper=dataind['oepsp'].quantile(0.999,
interpolation="higher"))
dataind['oepspw'].describe()
dataind['oepsp'].describe()
#dataind['epspw']=winsorize(dataind['epsp'],(0.01,0.99), nan_policy='omit')
# It seems that winsorize has problems with NaN values; it did not work
#I will use the clip method of pandas to do the winsorization:
dataind['oepspw']=dataind['oepsp'].clip(lower=dataind['oepsp'].quantile(0.008,
interpolation="lower"),
upper=dataind['oepsp'].quantile(0.999,
interpolation="higher"))
dataind['oepspw'].describe()
plt.clf()
sns.histplot(data=dataind,x='oepspw')
plt.show()
XY = dataind[["f1ry","epspw","oepspw","bmrw","revgrowthw","egrowthw","pmw","atow","sizeg_medium","sizeg_large"]]
XY[["f1ry","epspw","oepspw","bmrw","revgrowthw","egrowthw","pmw","atow"]].describe()
View(dataind)
dataind['revgrowth'].describe()
dataind['revgrowthw']=dataind['revgrowth'].clip(lower=dataind['revgrowth'].quantile(0.0005,interpolation="lower"),
upper=dataind['revgrowth'].quantile(0.985,
interpolation="higher"))
dataind['revgrowthw'].describe()
plt.clf()
sns.histplot(data=dataind,x='revgrowthw')
plt.show()
dataind['egrowth'].describe()
dataind['egrowthw']=dataind['egrowth'].clip(lower=dataind['egrowth'].quantile(0.01,interpolation="lower"),
upper=dataind['egrowth'].quantile(0.985,
interpolation="higher"))
dataind['egrowthw'].describe()
plt.clf()
sns.histplot(data=dataind,x='egrowthw')
plt.show()
dataind['pm'].describe()
dataind['pmw']=dataind['pm'].clip(lower=dataind['pm'].quantile(0.02,interpolation="lower"),
upper=dataind['pm'].quantile(0.999,
interpolation="higher"))
dataind['pmw'].describe()
plt.clf()
sns.histplot(data=dataind,x='pmw')
plt.show()
View(dataind)
XY = dataind[["f1ry","epspw","oepspw","bmrw","revgrowthw","egrowthw","pmw","atow","sizeg_medium","sizeg_large"]]
XY[["f1ry","epspw","oepspw","bmrw","revgrowthw","egrowthw","pmw","atow"]].describe()
import seaborn as sns
import matplotlib.pyplot as plt
#from scipy.stats.mstats import winsorize
dataind['epsp'].describe()
#dataind['epspw']=winsorize(dataind['epsp'],(0.01,0.99), nan_policy='omit')
# It seems that winsorize has problems with NaN values; it did not work
#I will use the clip method of pandas to do the winsorization:
dataind['epspw']=dataind['epsp'].clip(lower=dataind['epsp'].quantile(0.008,
interpolation="lower"),
upper=dataind['epsp'].quantile(0.999,
interpolation="higher"))
dataind['epspw'].describe()
plt.clf()
sns.histplot(data=dataind,x='epspw')
plt.show()
XY = dataind[["f1ry","epspw","oepspw","bmrw","revgrowthw","egrowthw","pmw","atow","sizeg_medium","sizeg_large"]]
XY[["f1ry","epspw","oepspw","bmrw","revgrowthw","egrowthw","pmw","atow"]].describe()
dataind['bmr'].describe()
dataind['bmrw']=dataind['bmr'].clip(lower=dataind['bmr'].quantile(0.002,
interpolation="lower"),
upper=dataind['bmr'].quantile(0.995,
interpolation="higher"))
dataind['bmrw'].describe()
plt.clf()
sns.histplot(data=dataind,x='bmrw')
plt.show()
XY = dataind[["f1ry","epspw","oepspw","bmrw","revgrowthw","egrowthw","pmw","atow","sizeg_medium","sizeg_large"]]
XY[["f1ry","epspw","oepspw","bmrw","revgrowthw","egrowthw","pmw","atow"]].describe()
import seaborn as sn
import matplotlib.pyplot as plt
corr_matrix = dataind[["F1ret","epspw","oepspw","bmrw","revgrowthw","egrowthw","pmw","atow","sizeg_medium","sizeg_large"]].corr()
sn.heatmap(corr_matrix, annot=True)
plt.show()
import seaborn as sn
import matplotlib.pyplot as plt
corr_matrix = dataind[["f1yr","epspw","oepspw","bmrw","revgrowthw","egrowthw","pmw","atow","sizeg_medium","sizeg_large"]].corr()
sn.heatmap(corr_matrix, annot=True)
plt.show()
import seaborn as sn
import matplotlib.pyplot as plt
corr_matrix = dataind[["f1ry","epspw","oepspw","bmrw","revgrowthw","egrowthw","pmw","atow","sizeg_medium","sizeg_large"]].corr()
sn.heatmap(corr_matrix, annot=True)
plt.show()
XY = dataind[["f1ry","epspw","oepspw","bmrw","revgrowthw","egrowthw","pmw","atow","sizeg_medium","sizeg_large"]].copy()
X = XY.drop(axis=1,columns=['f1ry'])
View(X)
X=sm.add_constant(X)
from statsmodels.stats.outliers_influence import variance_inflation_factor
import statsmodels.api as sm
import statsmodels.api as sm
X=sm.add_constant(X)
View(X)
vif_data = pd.DataFrame()
vif_data = pd.DataFrame()
vif_data["variable"] = X.columns
vif_data["variable"] = X.columns
# calculating VIF for each variable
vif_data = pd.DataFrame(dtype=float64)
vif_data = pd.DataFrame(dtype=float64)
vif_data["variable"] = X.columns
vif_data = pd.DataFrame(dtype='float64')
vif_data["variable"] = X.columns
vif_data["VIF"] = [variance_inflation_factor(X.dropna().values, i)
print(vif_data)
from statsmodels.stats.outliers_influence import variance_inflation_factor
# I import the library to run the regression model:
import statsmodels.api as sm
# I create a dataset with the indepdendent variables:
X = XY.drop(axis=1,columns=['f1ry'])
# I add a column of 1's to the X dataframe to include the constant (beta0) in the model
X=sm.add_constant(X)
# VIF dataframe
vif_data = pd.DataFrame(dtype='float64')
vif_data["variable"] = X.columns
# calculating VIF for each variable
vif_data["VIF"] = [variance_inflation_factor(X.dropna().values, i)
for i in range(len(X.columns))]
print(vif_data)
from statsmodels.stats.outliers_influence import variance_inflation_factor
# I import the library to run the regression model:
import statsmodels.api as sm
# I create a dataset with the indepdendent variables:
X = XY.drop(axis=1,columns=['f1ry'])
# VIF dataframe
vif_data = pd.DataFrame(dtype='float64')
vif_data["variable"] = X.columns
# calculating VIF for each variable
vif_data["VIF"] = [variance_inflation_factor(X.dropna().values, i)
for i in range(len(X.columns))]
print(vif_data)
# I add a column of 1's to the X dataframe to include the constant (beta0) in the model
X=sm.add_constant(X)
import statsmodels.api as sm
Y = XY['f1ry'].copy()
print(model1.summary())
Y = XY['f1ry'].copy()
Y = XY['f1ry'].to_frame()
model1 = sm.OLS(Y,X,missing='drop').fit()
print(model1.summary())
X.drop(axis=1,columns=['oepspw'],inplace=True)
View(X)
model1 = sm.OLS(Y,X,missing='drop').fit()
print(model1.summary())
import statsmodels.api as sm
# I estimate the model
model1 = sm.OLS.from_formula('f1ry ~ epspw + bmrw + revgrowthw + egrowthw + pmw + atow + sizeg_medium + siezeg_large + sizeg_medium:epspw + sizeg_large:epspw',data=XY,missing='drop').fit()
print(model1.summary())
View(XY)
XY=sm.add_constant(XY)
View(XY)
model1 = sm.OLS.from_formula('f1ry ~ epspw + bmrw + revgrowthw + egrowthw + pmw + atow + sizeg_medium + siezeg_large + sizeg_medium:epspw + sizeg_large:epspw',data=XY,missing='drop').fit()
import statsmodels.api as sm
XY=sm.add_constant(XY)
# I estimate the model
model1 = sm.OLS.from_formula('f1ry ~ epspw + bmrw + revgrowthw + egrowthw + pmw + atow + sizeg_medium + siezeg_large + sizeg_medium:epspw + sizeg_large:epspw',XY,missing='drop').fit()
print(model1.summary())
model1 = sm.OLS.from_formula('f1ry ~ epspw + bmrw + revgrowthw + egrowthw + pmw + atow + sizeg_medium + siezeg_large + sizeg_medium:epspw + sizeg_large:epspw',XY,missing='drop').fit()
model1 = sm.OLS.from_formula('f1ry ~ epspw + bmrw + revgrowthw + egrowthw + pmw + atow + sizeg_medium + sizeg_large + sizeg_medium:epspw + sizeg_large:epspw',data=XY,missing='drop').fit()
print(model1.summary())
import statsmodels.api as sm
XY=sm.add_constant(XY)
# I estimate the model
model1 = sm.OLS.from_formula('f1ry ~ oepspw + bmrw + revgrowthw + egrowthw + pmw + atow + sizeg_medium + sizeg_large + sizeg_medium:oepspw + sizeg_large:oepspw',data=XY,missing='drop').fit()
print(model1.summary())
import statsmodels.api as sm
XYc=sm.add_constant(XY)
# I estimate the model
model1 = sm.OLS.from_formula('f1ry ~ oepspw + bmrw + revgrowthw + egrowthw + pmw + atow + sizeg_medium + sizeg_large',data=XYc,missing='drop').fit()
print(model1.summary())
import statsmodels.api as sm
# I estimate the model
model2 = sm.OLS.from_formula('f1ry ~ oepspw + bmrw + revgrowthw + egrowthw + pmw + atow + sizeg_medium + sizeg_large + sizeg_medium:oepspw + sizeg_large:oepspw',data=XYc,missing='drop').fit()
print(model2.summary())
print(0.0613+0.0383)
print(0.6519-0.1950)
print(0.0613+0.1140)
print(0.6519-0.8432)
XY2022 = dataind[["f1ry","epspw","oepspw","bmrw","revgrowthw","egrowthw","pmw","atow","sizeg_medium","sizeg_large"]].loc['yearf'==2022].copy()
XY2022 = dataind[["yearf","f1ry","epspw","oepspw","bmrw","revgrowthw","egrowthw","pmw","atow","sizeg_medium","sizeg_large"]].loc['yearf'==2022].copy()
XY2022 = dataind[["yearf","f1ry","epspw","oepspw","bmrw","revgrowthw","egrowthw","pmw","atow","sizeg_medium","sizeg_large"]].loc['yearf']==2022
XY2022 = dataind.loc[dataind['yearf']==2022]
XY2022 = XY[["f1ry","epspw","oepspw","bmrw","revgrowthw","egrowthw","pmw","atow","sizeg_medium","sizeg_large"]]
XY2022 = dataind.loc[dataind['yearf']==2022].copy()
XY2022 = XY[["f1ry","epspw","oepspw","bmrw","revgrowthw","egrowthw","pmw","atow","sizeg_medium","sizeg_large"]]
XY2022 = dataind[dataind['yearf']==2022].copy()
XY2022 = XY[["f1ry","epspw","oepspw","bmrw","revgrowthw","egrowthw","pmw","atow","sizeg_medium","sizeg_large"]]
XY2022 = dataind[dataind['yearf']==2022].copy()
XY2022 = dataind[dataind['yearf']==2022].copy()
XY2022 = XY[["firm","f1ry","epspw","oepspw","bmrw","revgrowthw","egrowthw","pmw","atow","sizeg_medium","sizeg_large"]]
data.columns
data.index
datay.index
dataind.index
XY2022.index
XY2022 = dataind[dataind['yearf']==2022].copy()
XY2022.columns
XY2022.index
XY2022.reset_index(inplace=True)
XY2022.index
XY2022.columns
XY2022 = XY2022[["firm","f1ry","epspw","oepspw","bmrw","revgrowthw","egrowthw","pmw","atow","sizeg_medium","sizeg_large"]]
XY2022.set_index(['firm'], inplace=True)
XY2022.index
XY2022.head(4)
XY2022c = sm.add_constant(XY2022)
model3 = sm.OLS.from_formula('f1ry ~ oepspw + bmrw + revgrowthw + egrowthw + pmw + atow + sizeg_medium + sizeg_large + sizeg_medium:oepspw + sizeg_large:oepspw',data=XY2022c,missing='drop').fit()
print(model3.summary())
XY2022=XY2022.dropna()
XY2022.shape
X=XY2022[["epspw","oepspw","bmrw","revgrowthw","egrowthw","pmw","atow","sizeg_medium","sizeg_large"]]
Y = XY2022["f1ry"]
Y = XY2022["f1ry"].to_frame()
type(Y)
n = X.shape[0]
Ex2 = X.transpose() @ X / (n-1)
Ex2
Mx = X.mean()
Mx
Mx.shape
Mx2= np.outer(Mx,Mx.transpose())
Mx2
COV = Ex2 - n/(n-1) * Mx2
COV
cov1=X.cov()
type(cov1)
cov1
SD = np.sqrt(np.diag(COV))
SD
# i can check whether the calculated standard deviations are correct:
X.std()
D =np.diag(SD)
D
CORR = np.linalg.inv(D) @ COV @ np.linalg.inv(D)
CORR
corr1 = X.corr()
corr1
sn.heatmap(corr1, annot=True)
plt.show()
View(X)
# Add the constant to X1:
X1=sm.add_constant(X)
# Calculate the Hat matrix:
# H = X (X'X)^(-1) X':
H = np.dot(X1,np.dot(np.linalg.inv(np.dot(X1.transpose(),X1)),X1.transpose()))
# I could use also np.matmul instead of np.dot or @
#H2 = np.matmul(X1,np.matmul(np.linalg.inv(np.matmul(X1.transpose(),X1)),X1.transpose()))
# H2 endup as a dataframe, and H ends up as an array of (nxn) dimension
H.shape
